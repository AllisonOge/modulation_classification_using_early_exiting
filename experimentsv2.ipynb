{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getModel import blModel, eeModel, eeModel_V0, eeModel_V1, eeModel_V2, eeModel_V3\n",
    "from trainerv2 import Handler\n",
    "\n",
    "# training tools\n",
    "from model_builder.core.metrics import multiclass_accuracy\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "# data tools\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/RML22.pickle.01A', 'rb') as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = [lst[0] for lst in data.keys()]\n",
    "snrs = [lst[1] for lst in data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 210)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mods), len(snrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420000, 2, 128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for mod, snr in zip(mods, snrs):\n",
    "    # print(data[(mod, snr)].shape, mod, snr)\n",
    "    dataset.extend(data[(mod, snr)])\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "dataset.shape  # (210*2000, 2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(mods))\n",
    "name2label = {name: i for i, name in enumerate(np.unique(mods))}\n",
    "labels = torch.from_numpy(np.array([name2label[name] for name in mods]))\n",
    "labels = labels.repeat_interleave(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQDataset:\n",
    "    def __init__(self, x, y, transform_x=None, transform_y=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform_x = transform_x\n",
    "        self.transform_y = transform_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        if self.transform_x:\n",
    "            x = self.transform_x(x)\n",
    "        elif isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x)\n",
    "        if self.transform_y:\n",
    "            y = self.transform_y(y)\n",
    "        elif isinstance(y, np.ndarray):\n",
    "            y = torch.from_numpy(y)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151200, 100800, 168000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.4, random_state=0)\n",
    "dev_idx, test_idx = next(sss.split(dataset, labels))\n",
    "train_idx, val_idx = next(sss.split(dataset[dev_idx], labels[dev_idx]))\n",
    "\n",
    "train_data = IQDataset(\n",
    "    dataset[train_idx], labels[train_idx])\n",
    "val_data = IQDataset(\n",
    "    dataset[val_idx], labels[val_idx])\n",
    "test_data = IQDataset(\n",
    "    dataset[test_idx], labels[test_idx])\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128]), torch.Size([]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_x, one_y = train_data[0]\n",
    "one_x.shape, one_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blModel(\n",
      "  (baseModel): Sequential(\n",
      "    (0): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "  )\n",
      "  (longBranch): Sequential(\n",
      "    (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "blNet = blModel()\n",
    "print(blNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Epoch: 1, train_loss: 1.4886, val_loss: 1.1581, multiclass_accuracy: 0.4882, time: 00:00:20<p>Epoch: 2, train_loss: 1.5005, val_loss: 1.1996, multiclass_accuracy: 0.4781, time: 00:00:20<p>Epoch: 3, train_loss: 1.4703, val_loss: 1.1287, multiclass_accuracy: 0.4939, time: 00:00:21<p>Epoch: 4, train_loss: 1.4867, val_loss: 1.1494, multiclass_accuracy: 0.4872, time: 00:00:22<p>Epoch: 5, train_loss: 1.4571, val_loss: 1.1246, multiclass_accuracy: 0.4962, time: 00:00:22<p>Epoch: 6, train_loss: 1.4726, val_loss: 1.1329, multiclass_accuracy: 0.4887, time: 00:00:22<p>Epoch: 7, train_loss: 1.4670, val_loss: 1.1211, multiclass_accuracy: 0.4968, time: 00:00:22<p>Epoch: 8, train_loss: 1.4783, val_loss: 1.1454, multiclass_accuracy: 0.4971, time: 00:00:22<p>Epoch: 9, train_loss: 1.4514, val_loss: 1.1150, multiclass_accuracy: 0.5004, time: 00:00:22<p>Epoch: 10, train_loss: 1.4653, val_loss: 1.1315, multiclass_accuracy: 0.4948, time: 00:00:22<p>Epoch: 11, train_loss: 1.4448, val_loss: 1.1167, multiclass_accuracy: 0.5008, time: 00:00:22<p>Epoch: 12, train_loss: 1.4537, val_loss: 1.1182, multiclass_accuracy: 0.4923, time: 00:00:22<p>Epoch: 13, train_loss: 1.4466, val_loss: 1.1143, multiclass_accuracy: 0.4996, time: 00:00:22<p>Epoch: 14, train_loss: 1.4679, val_loss: 1.1219, multiclass_accuracy: 0.4948, time: 00:00:22<p>Epoch: 15, train_loss: 1.4567, val_loss: 1.1141, multiclass_accuracy: 0.5021, time: 00:00:22<p>Epoch: 16, train_loss: 1.4546, val_loss: 1.1178, multiclass_accuracy: 0.4946, time: 00:00:22<p>Epoch: 17, train_loss: 1.4453, val_loss: 1.1156, multiclass_accuracy: 0.5017, time: 00:00:22<p>Epoch: 18, train_loss: 1.4548, val_loss: 1.1123, multiclass_accuracy: 0.5003, time: 00:00:22<p>Epoch: 19, train_loss: 1.4399, val_loss: 1.1080, multiclass_accuracy: 0.5012, time: 00:00:22<p>Epoch: 20, train_loss: 1.4441, val_loss: 1.1051, multiclass_accuracy: 0.4975, time: 00:00:22<p>Epoch: 21, train_loss: 1.4510, val_loss: 1.1097, multiclass_accuracy: 0.5016, time: 00:00:22<p>Epoch: 22, train_loss: 1.4525, val_loss: 1.1104, multiclass_accuracy: 0.4932, time: 00:00:22<p>Epoch: 23, train_loss: 1.4397, val_loss: 1.1111, multiclass_accuracy: 0.5018, time: 00:00:22<p>Epoch: 24, train_loss: 2350.1897, val_loss: 959.7045, multiclass_accuracy: 0.1669, time: 00:00:22<p>Epoch: 25, train_loss: 1.8120, val_loss: 1.7983, multiclass_accuracy: 0.1655, time: 00:00:22<p>Epoch: 26, train_loss: 1.7930, val_loss: 1.7947, multiclass_accuracy: 0.1693, time: 00:00:22<p>Epoch: 27, train_loss: 1.7919, val_loss: 1.7948, multiclass_accuracy: 0.1662, time: 00:00:22<p>Epoch: 28, train_loss: 1.7930, val_loss: 1.7938, multiclass_accuracy: 0.1677, time: 00:00:22<p>Epoch: 29, train_loss: 1.7928, val_loss: 1.7957, multiclass_accuracy: 0.1656, time: 00:00:22<p>Epoch: 30, train_loss: 1.8328, val_loss: 1.8402, multiclass_accuracy: 0.1674, time: 00:00:22<p>Epoch: 31, train_loss: 1.7948, val_loss: 1.7941, multiclass_accuracy: 0.1657, time: 00:00:22<p>Epoch: 32, train_loss: 1.7926, val_loss: 1.7931, multiclass_accuracy: 0.1656, time: 00:00:22<p>Epoch: 33, train_loss: 1.7938, val_loss: 1.7932, multiclass_accuracy: 0.1656, time: 00:00:22<p>Epoch: 34, train_loss: 1.7957, val_loss: 1.7984, multiclass_accuracy: 0.1641, time: 00:00:22<p>Epoch: 35, train_loss: 1.7927, val_loss: 1.7933, multiclass_accuracy: 0.1663, time: 00:00:22<p>Epoch: 36, train_loss: 1.8466, val_loss: 1.8336, multiclass_accuracy: 0.1686, time: 00:00:22<p>Epoch: 37, train_loss: 1.7939, val_loss: 1.7935, multiclass_accuracy: 0.1654, time: 00:00:22<p>Epoch: 38, train_loss: 1.8029, val_loss: 1.8078, multiclass_accuracy: 0.1666, time: 00:00:22<p>Epoch: 39, train_loss: 1.8015, val_loss: 1.8051, multiclass_accuracy: 0.1703, time: 00:00:22<p>Epoch: 40, train_loss: 1.8017, val_loss: 1.7994, multiclass_accuracy: 0.1658, time: 00:00:22<p>Epoch: 41, train_loss: 1.7934, val_loss: 1.7931, multiclass_accuracy: 0.1649, time: 00:00:22<p>Epoch: 42, train_loss: 1.7995, val_loss: 1.8019, multiclass_accuracy: 0.1650, time: 00:00:22<p>Epoch: 43, train_loss: 1.7930, val_loss: 1.7927, multiclass_accuracy: 0.1691, time: 00:00:22<p>Epoch: 44, train_loss: 1.8027, val_loss: 1.8025, multiclass_accuracy: 0.1643, time: 00:00:22<p>Epoch: 45, train_loss: 1.8010, val_loss: 1.8022, multiclass_accuracy: 0.1662, time: 00:00:22<p>Epoch: 46, train_loss: 1.7998, val_loss: 1.8027, multiclass_accuracy: 0.1671, time: 00:00:22<p>Epoch: 47, train_loss: 1.7931, val_loss: 1.7930, multiclass_accuracy: 0.1649, time: 00:00:22<p>Epoch: 48, train_loss: 1.8022, val_loss: 1.8035, multiclass_accuracy: 0.1660, time: 00:00:22<p>Epoch: 49, train_loss: 1.7930, val_loss: 1.7927, multiclass_accuracy: 0.1685, time: 00:00:22<p>Epoch: 50, train_loss: 1.8034, val_loss: 1.7993, multiclass_accuracy: 0.1674, time: 00:00:22"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with val_loss value: 1.1580520868301392.\n",
      "Better model found at epoch 2 with val_loss value: 1.128730058670044.\n",
      "Better model found at epoch 4 with val_loss value: 1.124612808227539.\n",
      "Better model found at epoch 6 with val_loss value: 1.121091604232788.\n",
      "Better model found at epoch 8 with val_loss value: 1.1149768829345703.\n",
      "Reducing LR to 0.0001.\n",
      "Better model found at epoch 12 with val_loss value: 1.1142569780349731.\n",
      "Better model found at epoch 14 with val_loss value: 1.114080786705017.\n",
      "Better model found at epoch 17 with val_loss value: 1.1122633218765259.\n",
      "Better model found at epoch 18 with val_loss value: 1.1080347299575806.\n",
      "Better model found at epoch 19 with val_loss value: 1.1050848960876465.\n",
      "Reducing LR to 1e-05.\n",
      "Reducing LR to 1.0000000000000002e-06.\n",
      "Reducing LR to 1.0000000000000002e-07.\n",
      "Reducing LR to 1.0000000000000004e-08.\n",
      "Reducing LR to 1.0000000000000005e-09.\n",
      "Reducing LR to 1.0000000000000006e-10.\n",
      "Reducing LR to 1.0000000000000006e-11.\n",
      "Reducing LR to 1.0000000000000006e-12.\n",
      "Reducing LR to 1.0000000000000007e-13.\n",
      "Reducing LR to 1.0000000000000008e-14.\n",
      "\n",
      "\n",
      "Training completed\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.10531 Multiclass Accuracy: 0.498\n",
      "Model saved at: Models/blModel.pt\n"
     ]
    }
   ],
   "source": [
    "hdl = Handler(blNet, nepochs=NUM_EPOCHS, crit=cross_entropy,\n",
    "              sch=\"cosine\", modelPath='./Models/', modelName=\"blModel\")\n",
    "hdl.train(train_data, val_data, bs=64, lr=1e-3,\n",
    "          wd=1e-4, metric_name='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EE Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of base parameters: 576\n",
      "Number of short branch parameters: 68010\n",
      "Number of long branch parameters: 118842\n",
      "Difference = 50832\n",
      "eeModel_V0(\n",
      "  (baseModel): Sequential(\n",
      "    (0): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (shortBranch): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      "  (longBranch): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (14): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Flatten(start_dim=1, end_dim=-1)\n",
      "    (18): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (19): Dropout(p=0.5, inplace=False)\n",
      "    (20): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (21): Dropout(p=0.5, inplace=False)\n",
      "    (22): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eev0Net = eeModel_V0()\n",
    "print(eev0Net)\n",
    "\n",
    "one_y1, one_y2 = eev0Net(one_x.unsqueeze(0))\n",
    "one_y1.shape, one_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(outputs, target, reduction=\"mean\"):\n",
    "    out1, out2 = outputs\n",
    "    return (cross_entropy(out1, target, reduction=reduction) + cross_entropy(out2, target, reduction=reduction)) / 2\n",
    "\n",
    "\n",
    "def accuracy(outputs, target):\n",
    "    out1, out2 = outputs\n",
    "    return (multiclass_accuracy(out1, target) + multiclass_accuracy(out2, target)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Epoch: 1, train_loss: 1.6399, val_loss: 1.4749, accuracy: 0.3308, time: 00:00:25<p>Epoch: 2, train_loss: 1.6442, val_loss: 1.4960, accuracy: 0.3250, time: 00:00:25<p>Epoch: 3, train_loss: 1.6072, val_loss: 1.4322, accuracy: 0.3516, time: 00:00:25<p>Epoch: 4, train_loss: 1.6035, val_loss: 1.3850, accuracy: 0.3725, time: 00:00:25<p>Epoch: 5, train_loss: 1.5709, val_loss: 1.3373, accuracy: 0.3867, time: 00:00:25<p>Epoch: 6, train_loss: 1.5951, val_loss: 1.3905, accuracy: 0.3763, time: 00:00:25<p>Epoch: 7, train_loss: 1.5514, val_loss: 1.3231, accuracy: 0.3904, time: 00:00:25<p>Epoch: 8, train_loss: 1.5847, val_loss: 1.3897, accuracy: 0.3754, time: 00:00:25<p>Epoch: 9, train_loss: 1.5531, val_loss: 1.3319, accuracy: 0.3904, time: 00:00:25<p>Epoch: 10, train_loss: 1.5691, val_loss: 1.3787, accuracy: 0.3813, time: 00:00:25<p>Epoch: 11, train_loss: 1.5477, val_loss: 1.3754, accuracy: 0.3882, time: 00:00:25<p>Epoch: 12, train_loss: 1.5596, val_loss: 1.4328, accuracy: 0.3663, time: 00:00:25<p>Epoch: 13, train_loss: 1.5482, val_loss: 1.3804, accuracy: 0.3893, time: 00:00:25<p>Epoch: 14, train_loss: 735.1983, val_loss: 404.9314, accuracy: 0.1653, time: 00:00:25<p>Epoch: 15, train_loss: 1.7948, val_loss: 1.7926, accuracy: 0.1685, time: 00:00:25<p>Epoch: 16, train_loss: 1.7934, val_loss: 1.7923, accuracy: 0.1662, time: 00:00:25<p>Epoch: 17, train_loss: 1.7919, val_loss: 1.7925, accuracy: 0.1657, time: 00:00:25<p>Epoch: 18, train_loss: 1.7927, val_loss: 1.7926, accuracy: 0.1667, time: 00:00:25<p>Epoch: 19, train_loss: 1.7925, val_loss: 1.7922, accuracy: 0.1671, time: 00:00:25<p>Epoch: 20, train_loss: 1.8620, val_loss: 1.8701, accuracy: 0.1669, time: 00:00:25<p>Epoch: 21, train_loss: 1.7921, val_loss: 1.7927, accuracy: 0.1673, time: 00:00:25<p>Epoch: 22, train_loss: 1.7926, val_loss: 1.7924, accuracy: 0.1670, time: 00:00:25<p>Epoch: 23, train_loss: 1.8021, val_loss: 1.7924, accuracy: 0.1670, time: 00:00:25<p>Epoch: 24, train_loss: 1.7949, val_loss: 1.7954, accuracy: 0.1659, time: 00:00:25<p>Epoch: 25, train_loss: 1.7921, val_loss: 1.7920, accuracy: 0.1668, time: 00:00:25<p>Epoch: 26, train_loss: 1.8022, val_loss: 1.8022, accuracy: 0.1658, time: 00:00:25<p>Epoch: 27, train_loss: 1.7924, val_loss: 1.7920, accuracy: 0.1669, time: 00:00:25<p>Epoch: 28, train_loss: 1.7941, val_loss: 1.7943, accuracy: 0.1670, time: 00:00:25<p>Epoch: 29, train_loss: 1.7939, val_loss: 1.7943, accuracy: 0.1669, time: 00:00:25<p>Epoch: 30, train_loss: 1.7942, val_loss: 1.7930, accuracy: 0.1665, time: 00:00:25<p>Epoch: 31, train_loss: 1.7922, val_loss: 1.7920, accuracy: 0.1676, time: 00:00:25<p>Epoch: 32, train_loss: 1.7934, val_loss: 1.7934, accuracy: 0.1663, time: 00:00:25<p>Epoch: 33, train_loss: 1.7924, val_loss: 1.7921, accuracy: 0.1660, time: 00:00:25<p>Epoch: 34, train_loss: 1.7933, val_loss: 1.7922, accuracy: 0.1664, time: 00:00:25<p>Epoch: 35, train_loss: 1.7916, val_loss: 1.7923, accuracy: 0.1661, time: 00:00:25<p>Epoch: 36, train_loss: 1.7920, val_loss: 1.7941, accuracy: 0.1659, time: 00:00:25<p>Epoch: 37, train_loss: 1.7921, val_loss: 1.7920, accuracy: 0.1664, time: 00:00:25<p>Epoch: 38, train_loss: 1.7931, val_loss: 1.7928, accuracy: 0.1654, time: 00:00:25<p>Epoch: 39, train_loss: 1.7921, val_loss: 1.7918, accuracy: 0.1665, time: 00:00:25<p>Epoch: 40, train_loss: 1.7927, val_loss: 1.7925, accuracy: 0.1657, time: 00:00:25<p>Epoch: 41, train_loss: 1.7922, val_loss: 1.7926, accuracy: 0.1663, time: 00:00:25<p>Epoch: 42, train_loss: 1.7928, val_loss: 1.7925, accuracy: 0.1675, time: 00:00:25<p>Epoch: 43, train_loss: 1.7919, val_loss: 1.7918, accuracy: 0.1676, time: 00:00:25<p>Epoch: 44, train_loss: 1.7924, val_loss: 1.7921, accuracy: 0.1680, time: 00:00:25<p>Epoch: 45, train_loss: 1.7918, val_loss: 1.7919, accuracy: 0.1668, time: 00:00:25<p>Epoch: 46, train_loss: 1.7923, val_loss: 1.7926, accuracy: 0.1691, time: 00:00:25<p>Epoch: 47, train_loss: 1.7931, val_loss: 1.7926, accuracy: 0.1680, time: 00:00:24<p>Epoch: 48, train_loss: 1.7925, val_loss: 1.7921, accuracy: 0.1660, time: 00:00:24<p>Epoch: 49, train_loss: 1.7919, val_loss: 1.7919, accuracy: 0.1656, time: 00:00:24<p>Epoch: 50, train_loss: 1.7924, val_loss: 1.7923, accuracy: 0.1654, time: 00:00:24"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with val_loss value: 1.4748704433441162.\n",
      "Better model found at epoch 2 with val_loss value: 1.4322011470794678.\n",
      "Better model found at epoch 3 with val_loss value: 1.3850140571594238.\n",
      "Better model found at epoch 4 with val_loss value: 1.3373169898986816.\n",
      "Better model found at epoch 6 with val_loss value: 1.3231210708618164.\n",
      "Reducing LR to 0.0001.\n",
      "Reducing LR to 1e-05.\n",
      "Reducing LR to 1.0000000000000002e-06.\n",
      "Reducing LR to 1.0000000000000002e-07.\n",
      "Reducing LR to 1.0000000000000004e-08.\n",
      "Reducing LR to 1.0000000000000005e-09.\n",
      "Reducing LR to 1.0000000000000006e-10.\n",
      "Reducing LR to 1.0000000000000006e-11.\n",
      "Reducing LR to 1.0000000000000006e-12.\n",
      "Reducing LR to 1.0000000000000007e-13.\n",
      "Reducing LR to 1.0000000000000008e-14.\n",
      "Reducing LR to 1.0000000000000009e-15.\n",
      "Reducing LR to 1.000000000000001e-16.\n",
      "Reducing LR to 1.000000000000001e-17.\n",
      "\n",
      "\n",
      "Training completed\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.32317 Accuracy: 0.389\n",
      "Model saved at: Models/eev0Model.pt\n"
     ]
    }
   ],
   "source": [
    "hdl = Handler(eev0Net, nepochs=NUM_EPOCHS, crit=loss_func,\n",
    "              sch=\"cosine\", metrics=[accuracy], modelPath='./Models/', modelName=\"eev0Model\")\n",
    "hdl.train(train_data, val_data, bs=64, lr=1e-3,\n",
    "          wd=1e-4, metric_name=\"val_loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
